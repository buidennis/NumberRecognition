{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout,Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINST Data\n",
    "Data Points: { Image of handwritten digit, Corresponding label from [0, 9]}\n",
    "X, Image of the handwritten digit will be the input\n",
    "Y, Label Corresponding to the image\n",
    "( Hot-ones the numerical labels)\n",
    "\n",
    "Each image is written as 28 x 28 ( 784 pixels)\n",
    "We want to convert the 2D array into a 1D array\n",
    "Data loss is worth simplifying the data\n",
    "New array shape ( 60,000 , 784): 2D Array: ( Training images, pixel count)\n",
    "\n",
    "Sigmoid Activation: \n",
    "Object Oriented Design ( Encapsulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9525741268224334\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class Neuron( object):\n",
    "    def __init__(self):\n",
    "        self.weights = np.array( [ 1.0, 2.0])\n",
    "        self.bias = 0.0\n",
    "    def forward( self, inputs):\n",
    "        # Precondition: Inputs + Weights are 1D arrays ( numpy) and bias is float\n",
    "        # y = mx + b -> neuronSum = \\sum ( imageValues * classifierWeights + bias)\n",
    "        neuronSum = np.sum( inputs * self.weights) + self.bias\n",
    "        result = 1.0 / ( 1.0 + math.exp( -neuronSum))\n",
    "        # Sigmoid Activation Function: \n",
    "        return result\n",
    "    \n",
    "neuron = Neuron()\n",
    "output = neuron.forward(np.array([1,1]))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "X_test shape: (10000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "y_test shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Get the training and test data\n",
    "( X_train, y_train), ( X_test, y_test) = mnist.load_data()\n",
    "print( 'X_train shape:', X_train.shape)\n",
    "print( 'X_test shape:', X_test.shape)\n",
    "print( 'y_train shape:', y_train.shape)\n",
    "print( 'y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digit( index):\n",
    "    # Label: trainY at index i, finding the largest value in the columns\n",
    "    label = y_train[index].argmax(axis=0)\n",
    "    # Retrieve the i'th image from the training data\n",
    "    image = X_train[index]\n",
    "    # \n",
    "    plt.title('Training data, index: %d,  Label: %d'%(index,label))\n",
    "    plt.imshow(image,cmap='gray_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the matrix shape (60000, 784)\n",
      "Test the matrix shape (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.reshape(60000,784)\n",
    "X_test=X_test.reshape(10000,784)\n",
    "X_train=X_train.astype('float32')\n",
    "X_test=X_test.astype('float32')\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "print(\"Train the matrix shape\",X_train.shape)\n",
    "print(\"Test the matrix shape\",X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "print(y_train.shape)\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the neural network\n",
    "def build_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(512,input_shape=(784,)))\n",
    "    model.add( Activation( 'relu'))\n",
    "    # An “activation” is just a non-linear function that is applied to the output\n",
    "    # of the above layer. In this case, with a “rectified linear unit”,\n",
    "    # we perform clamping on all values below 0 to 0.\n",
    "    model.add(Dropout(0.2))\n",
    "    #With the help of Dropout helps we can protect the model from memorizing or “overfitting” the training data\n",
    "    model.add(Dense(512))\n",
    "    model.add( Activation( 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10))\n",
    "    model.add( Activation( 'softmax'))\n",
    "    # This special “softmax” activation,\n",
    "    #It also ensures that the output is a valid probability distribution,\n",
    "    #Meaning that values obtained are all non-negative and sum up to 1.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Building the model\n",
    "model=build_model()\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.2442 - acc: 0.9246 - val_loss: 0.1240 - val_acc: 0.9594\n",
      "Epoch 2/4\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1017 - acc: 0.9693 - val_loss: 0.0979 - val_acc: 0.9689\n",
      "Epoch 3/4\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0754 - acc: 0.9769 - val_loss: 0.0790 - val_acc: 0.9744\n",
      "Epoch 4/4\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.0609 - acc: 0.9810 - val_loss: 0.0743 - val_acc: 0.9791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e5f7783278>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(X_train,y_train,batch_size=128,nb_epoch=4,verbose=1,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 50us/step\n",
      "Test score: 0.07425303205654782\n",
      "Test accuracy: 0.9791\n"
     ]
    }
   ],
   "source": [
    "# Comparing the labels predicted by our model with the actual labels\n",
    "score=model.evaluate(X_test,y_test,batch_size=32,verbose=1,sample_weight=None)\n",
    "# Printing the result\n",
    "print('Test score:',score[0])\n",
    "print('Test accuracy:',score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
